{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handy-aquarium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td class=\"sessionId\">0</td><td>None</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"/spark/erin/40528/jobs\">Link</a></td><td></td><td>erin</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+---------------+------------+---------------+----------------+----------------+-------------+-----------------+----------+-------+-------+--------------+\n",
      "| id|home_team_id|home_team_score|away_team_id|away_team_score|away_team_scores|home_team_scores|number_of_ots|             date|attendance|playoff| season|         notes|\n",
      "+---+------------+---------------+------------+---------------+----------------+----------------+-------------+-----------------+----------+-------+-------+--------------+\n",
      "|  1|           1|             93|           8|             85|              []|              []|         null|Sat, Oct 29, 1949|      null|  false|1949-50|          null|\n",
      "|  2|          32|             87|          20|             89|              []|              []|         null| Tue, Nov 1, 1949|      null|  false|1949-50|          null|\n",
      "|  3|          33|             71|           8|             64|              []|              []|         null| Tue, Nov 1, 1949|      null|  false|1949-50|          null|\n",
      "|  4|          26|            108|          34|             75|              []|              []|         null| Tue, Nov 1, 1949|      null|  false|1949-50|          null|\n",
      "|  5|          35|             72|           1|             51|              []|              []|         null| Tue, Nov 1, 1949|      null|  false|1949-50|at Chicago, IL|\n",
      "+---+------------+---------------+------------+---------------+----------------+----------------+-------------+-----------------+----------+-------+-------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---+-------+-------+--------------+---+----+------+----+----+-------+---+----+------+----+----+----+----+----+----+----+----+---+\n",
      "| id|game_id|team_id|minutes_played| fg| fga|fg_pct| fg3|fg3a|fg3_pct| ft| fta|ft_pct| orb| drb| trb| ast| stl| blk| tov|  pf|pts|\n",
      "+---+-------+-------+--------------+---+----+------+----+----+-------+---+----+------+----+----+----+----+----+----+----+----+---+\n",
      "|  1|      1|      8|           240| 29|null|  null|null|null|   null| 27|null|  null|null|null|null|null|null|null|null|  35| 85|\n",
      "|  2|      1|      1|           240| 32|null|  null|null|null|   null| 29|null|  null|null|null|null|null|null|null|null|null| 93|\n",
      "|  3|      2|     20|           265| 28|null|  null|null|null|   null| 33|  47| 0.702|null|null|null|null|null|null|null|null| 89|\n",
      "|  4|      2|     32|           265| 32|null|  null|null|null|   null| 23|  42| 0.548|null|null|null|null|null|null|null|null| 87|\n",
      "|  5|      3|      8|           240| 19|null|  null|null|null|   null| 26|  31| 0.839|null|null|null|null|null|null|null|null| 64|\n",
      "+---+-------+-------+--------------+---+----+------+----+----+-------+---+----+------+----+----+----+----+----+----+----+----+---+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "df1 = spark.read.csv('hdfs://default/user/erin/all_game_scores.csv', sep=',',encoding='UTF-8',comment=None, header=True,inferSchema=True)\n",
    "df= spark.read.csv('hdfs://default/user/erin/team_game_data.csv', sep=',',encoding='UTF-8',comment=None, header=True,inferSchema=True)\n",
    "\n",
    "df1.show(5)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-exhibit",
   "metadata": {},
   "source": [
    "step1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-brand",
   "metadata": {},
   "source": [
    "**1.读入并组合两个csv表格**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-magic",
   "metadata": {},
   "source": [
    "**组合两个csv，将队伍的场次得分与队伍当场细节得分进行整合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compound-alert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+--------------+---+----+------+----+----+-------+---+----+------+----+----+----+----+----+----+----+----+---+------------+---------------+------------+---------------+-------------+-----------------+----------+-------+-------+-----+\n",
      "| id|game_id|team_id|minutes_played| fg| fga|fg_pct| fg3|fg3a|fg3_pct| ft| fta|ft_pct| orb| drb| trb| ast| stl| blk| tov|  pf|pts|home_team_id|home_team_score|away_team_id|away_team_score|number_of_ots|             date|attendance|playoff| season|notes|\n",
      "+---+-------+-------+--------------+---+----+------+----+----+-------+---+----+------+----+----+----+----+----+----+----+----+---+------------+---------------+------------+---------------+-------------+-----------------+----------+-------+-------+-----+\n",
      "|  1|      1|      8|           240| 29|null|  null|null|null|   null| 27|null|  null|null|null|null|null|null|null|null|  35| 85|           1|             93|           8|             85|         null|Sat, Oct 29, 1949|      null|  false|1949-50| null|\n",
      "|  2|      1|      1|           240| 32|null|  null|null|null|   null| 29|null|  null|null|null|null|null|null|null|null|null| 93|           1|             93|           8|             85|         null|Sat, Oct 29, 1949|      null|  false|1949-50| null|\n",
      "+---+-------+-------+--------------+---+----+------+----+----+-------+---+----+------+----+----+----+----+----+----+----+----+---+------------+---------------+------------+---------------+-------------+-----------------+----------+-------+-------+-----+\n",
      "only showing top 2 rows"
     ]
    }
   ],
   "source": [
    "df1=df1.withColumnRenamed(\"id\",\"did\")\n",
    "df=df.join(df1, df.game_id == df1.did)\n",
    "df=df.drop(\"did\",\"away_team_scores\",\"home_team_scores\")\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-characteristic",
   "metadata": {},
   "source": [
    "step2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-mainland",
   "metadata": {},
   "source": [
    "**2.精炼出特殊特征**\n",
    "- 1.每队的每场比赛是否胜利，如果胜利特征win为1，反之为0\n",
    "- 2.将string形式的日期调整格式并转化为datetime形式\n",
    "- 3.从datetime格式中提取月份，年份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "desperate-junior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.functions import  year,month\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "def datetrans1(a,b,c):\n",
    "    if a<b and c==1:\n",
    "        return 0\n",
    "    elif a>b and c==0:\n",
    "        return 0\n",
    "    else :\n",
    "        return 1\n",
    "\n",
    "def datetrans2(m):\n",
    "    date_object=datetime.strptime(m, '%b%d,%Y')\n",
    "    return date_object\n",
    "\n",
    "df = df.withColumn(\"home\", when(df.team_id == df.home_team_id,1)\n",
    "                                 .otherwise(0))\n",
    "\n",
    "func=udf(datetrans1,IntegerType())\n",
    "df=df.withColumn(\"win\",func(df.home_team_score,df.away_team_score,df.home))\n",
    "\n",
    "spaceDeleteUDF = udf(lambda s: s.replace(\" \", \"\"), StringType())\n",
    "df=df.withColumn(\"date\", spaceDeleteUDF(df.date))\n",
    "df=df.withColumn('date', df.date[5:20])\n",
    "\n",
    "\n",
    "func=udf(datetrans2,DateType())\n",
    "df=df.withColumn(\"realdate\",func(df.date))\n",
    "\n",
    "df=df.withColumn(\"month\",month(df.realdate))\n",
    "df=df.withColumn(\"year\",year(df.realdate))\n",
    "\n",
    "df=df.withColumn(\"curwin\",df[\"win\"])\n",
    "df=df.drop(\"minutes_played\",\"home_team_id\",\"home_team_score\",\"away_team_id\",\"away_team_score\",\"pts\",\"date\",\"notes\")\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-approval",
   "metadata": {},
   "source": [
    "step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-henry",
   "metadata": {},
   "source": [
    "**3.清洗重复数据**\n",
    "- 整行去重：data.distinct()这个方程可以对于完全相同的行进行去重。\n",
    "- dataframe.count()方程会打印出这个列表的行数，以便于您了解去重之后的数据集行数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "inside-reserve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128233"
     ]
    }
   ],
   "source": [
    "df=df.distinct()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "anticipated-engine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- game_id: integer (nullable = true)\n",
      " |-- team_id: integer (nullable = true)\n",
      " |-- fg: integer (nullable = true)\n",
      " |-- fga: integer (nullable = true)\n",
      " |-- fg_pct: double (nullable = true)\n",
      " |-- fg3: integer (nullable = true)\n",
      " |-- fg3a: integer (nullable = true)\n",
      " |-- fg3_pct: double (nullable = true)\n",
      " |-- ft: integer (nullable = true)\n",
      " |-- fta: integer (nullable = true)\n",
      " |-- ft_pct: double (nullable = true)\n",
      " |-- orb: integer (nullable = true)\n",
      " |-- drb: integer (nullable = true)\n",
      " |-- trb: integer (nullable = true)\n",
      " |-- ast: integer (nullable = true)\n",
      " |-- stl: integer (nullable = true)\n",
      " |-- blk: integer (nullable = true)\n",
      " |-- tov: integer (nullable = true)\n",
      " |-- pf: integer (nullable = true)\n",
      " |-- number_of_ots: integer (nullable = true)\n",
      " |-- attendance: integer (nullable = true)\n",
      " |-- playoff: boolean (nullable = true)\n",
      " |-- season: string (nullable = true)\n",
      " |-- home: integer (nullable = false)\n",
      " |-- win: integer (nullable = true)\n",
      " |-- realdate: date (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- curwin: integer (nullable = true)"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-falls",
   "metadata": {},
   "source": [
    "step4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-johnson",
   "metadata": {},
   "source": [
    "**4.将数据类别进行转化**\n",
    "- 以下这个单元格将一些列的数据种类进行了改变。您可以通过在withColumn这个方程来进行改变，在括号中填入您想要改变的列名，以及想改变成的种类形式。形式：（“列名”,dataframe[\"列名\"].cast('type')）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "designing-commissioner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-------+----+-----+------+----+----+-------+----+----+------+----+----+----+----+---+---+----+----+-------------+----------+-------+-------+----+---+----------+-----+------+------+\n",
      "|      id|game_id|team_id|  fg|  fga|fg_pct| fg3|fg3a|fg3_pct|  ft| fta|ft_pct| orb| drb| trb| ast|stl|blk| tov|  pf|number_of_ots|attendance|playoff| season|home|win|  realdate|month|  year|curwin|\n",
      "+--------+-------+-------+----+-----+------+----+----+-------+----+----+------+----+----+----+----+---+---+----+----+-------------+----------+-------+-------+----+---+----------+-----+------+------+\n",
      "|101752.0|50896.0|   20.0|45.0| 88.0| 0.511|11.0|24.0|  0.458|11.0|17.0| 0.647|10.0|36.0|46.0|25.0|5.0|2.0|13.0|16.0|          1.0|   17366.0|  false|2009-10| 0.0|1.0|2010-01-01|  1.0|2010.0|   1.0|\n",
      "|101753.0|50896.0|    1.0|46.0|100.0|  0.46| 7.0|27.0|  0.259| 9.0|14.0| 0.643|17.0|31.0|48.0|26.0|7.0|7.0|10.0|18.0|          1.0|   17366.0|  false|2009-10| 1.0|0.0|2010-01-01|  1.0|2010.0|   0.0|\n",
      "+--------+-------+-------+----+-----+------+----+----+-------+----+----+------+----+----+----+----+---+---+----+----+-------------+----------+-------+-------+----+---+----------+-----+------+------+\n",
      "only showing top 2 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "colNames = df.columns\n",
    "remove=['realdate','playoff','newplayoff','season']\n",
    "colNames= filter(lambda i: i not in remove, colNames)\n",
    "for colName in colNames:\n",
    "    df = df.withColumn(colName, col(colName).cast('double'))\n",
    "df=df.fillna(0)\n",
    "df=df.orderBy('id')\n",
    "df=df.filter(df.year>=2010)\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-prevention",
   "metadata": {},
   "source": [
    "step5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-completion",
   "metadata": {},
   "source": [
    "**5.对每列数据进行scale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "electric-freeware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import stddev, mean\n",
    "avgcol=['fg','fga','fg_pct','fg3','fg3a','fg3_pct','ft','fta','ft_pct','orb','drb','trb','ast','stl','blk','tov','pf','number_of_ots','attendance','win']\n",
    "for i in avgcol:\n",
    "    mean_amount, sttdev_amount = df.select(mean(i), stddev(i)).first()\n",
    "    str1='scaled'+i\n",
    "    df=df.withColumn(str1, (col(i) - mean_amount) / sttdev_amount)\n",
    "    df=df.drop(i)\n",
    "    df=df.withColumnRenamed(str1,i)\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-mayor",
   "metadata": {},
   "source": [
    "step6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-viewer",
   "metadata": {},
   "source": [
    "**6.将每队每场比赛的表现数据替换成最近八场比赛的平均数据**\n",
    "- 为了对比赛进行精准预测，通过function avg_previous_num_games对该队的该场比赛表现进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "finite-wiring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)"
     ]
    }
   ],
   "source": [
    "teams = df.select(\"team_id\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "pdf=df.toPandas()\n",
    "\n",
    "todaycol=['fg','fga','fg_pct','fg3','fg3a','fg3_pct','ft','fta','ft_pct','orb','drb','trb','ast','stl','blk','tov'\n",
    "      ,'pf','number_of_ots','attendance','win']\n",
    "def avg_previous_num_games(df,num_games):\n",
    "    for col in todaycol:\n",
    "        for team in teams:\n",
    "            df[col].loc[df['team_id'] == team]=df[col].loc[df['team_id']==team].shift(1).rolling(num_games,min_periods=3).mean()\n",
    "    return df.dropna()\n",
    "\n",
    "newpdf=avg_previous_num_games(pdf,8)\n",
    "df = spark.createDataFrame(newpdf)\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-century",
   "metadata": {},
   "source": [
    "step7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-rhythm",
   "metadata": {},
   "source": [
    "加入elo系数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-label",
   "metadata": {},
   "source": [
    "**7.将同属于同一场比赛的两队信息进行组合**\n",
    "- 将dataframe分成主场球队比赛数据dataframe和客场球队比赛数据dataframe，将两个dataframe基于打同一场比赛的信息合并，得到的最终dataframe每行数据为一场比赛的主场球队数据与客场球队数据，便于横向比较两个球队的实力区别，更准确地预测比赛输赢。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "confidential-civilization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success"
     ]
    }
   ],
   "source": [
    "dfhome=df.filter(df['home']==1)\n",
    "dfaway=df.filter(df['home']==0)\n",
    "\n",
    "cols2=['game_id','team_id','fg','fga','fg_pct','fg3','fg3a','fg3_pct','ft','fta','ft_pct','orb','drb','trb','ast','stl','blk','tov'\n",
    "      ,'pf','number_of_ots','attendance','win']\n",
    "dfaway=dfaway.select(*cols2)\n",
    "for i in cols2:\n",
    "    str1=\"new\"+i\n",
    "    dfaway=dfaway.withColumnRenamed(i,str1)\n",
    "\n",
    "dfhome=dfhome.join(dfaway, dfhome.game_id == dfaway.newgame_id)\n",
    "dfhome = dfhome.withColumn(\"game_id\",dfhome['game_id'].cast('int'))\n",
    "dfhome=dfhome.orderBy(dfhome['game_id'])\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-installation",
   "metadata": {},
   "source": [
    "**8.计算每队实时elo系数**\n",
    "- 根据每场比赛的输赢情况，以1600为起始elo参数，随着比赛输赢情况，让elo实时更新。\n",
    "- 因使用特征参数来预测比赛结果，若将每行比赛的输赢情况及时反馈到elo特征系数上，则会使比赛结果影响特征向量，而在预测结果时，假定的情况是比赛结果未知，并特征向量不被当场比赛结果影响，只被之前的比赛结果影响。\n",
    "- 因此每场比赛的team_rank先存于dict elo中，在打下场比赛时，dict中的实时更新的elo值赋予到dataframe的该行中，再根据比赛情况计算出新的team_rank,并在dict中更新参与比赛队伍的team_rank。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "base_elo = 1600\n",
    "dfhome=dfhome.withColumn(\"elo\",lit(base_elo))\n",
    "dfhome=dfhome.withColumn(\"newelo\",lit(base_elo))\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hungarian-munich",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "dfelo=dfhome.select(\"game_id\",\"team_id\",\"newteam_id\",\"curwin\",\"elo\",\"newelo\",\"season\")\n",
    "pdfelo=dfelo.toPandas()\n",
    "oldseason = \"2009-10\"\n",
    "elo={}\n",
    "teams = df.select(\"team_id\").distinct().rdd.flatMap(lambda x: x).collect()    \n",
    "seasons = dfhome.select(\"season\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "for i in seasons:\n",
    "    elo[i]={}\n",
    "    for j in teams:\n",
    "        elo[i][j]=1600.0\n",
    "\n",
    "def elofunc1(pdfelo):\n",
    "    for index,row in pdfelo.iterrows():\n",
    "        curwin=row['curwin']\n",
    "        teamid=row['team_id']\n",
    "        newteamid=row['newteam_id']\n",
    "        season=row['season']\n",
    "        if(curwin==1.0):\n",
    "            win_team=teamid\n",
    "            lose_team=newteamid\n",
    "        else:\n",
    "            win_team=newteamid\n",
    "            lose_team=teamid\n",
    "        \n",
    "        winner_rank = elo[season][win_team]\n",
    "        loser_rank = elo[season][lose_team]\n",
    "        rank_diff = winner_rank - loser_rank\n",
    "        exp = (rank_diff  * -1) / 400\n",
    "        odds = 1 / (1 + math.pow(10, exp))\n",
    "        # Alter K based on rank\n",
    "        if winner_rank < 2100:\n",
    "            k =32\n",
    "        elif winner_rank >= 2100 and winner_rank < 2400:\n",
    "            k =24\n",
    "        else:\n",
    "            k =16\n",
    "        new_winner_rank = round(winner_rank + (k * (1 - odds)))\n",
    "        new_loser_rank = round(loser_rank + (k * (0 - odds)))\n",
    "        pdfelo.loc[index,'elo']= float(elo[season][teamid])\n",
    "        pdfelo.loc[index,'newelo']= float(elo[season][newteamid])\n",
    "        elo[season][win_team]=new_winner_rank\n",
    "        elo[season][lose_team]=new_loser_rank\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "superior-engineer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "elofunc1(pdfelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ordinary-repair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- game_id: long (nullable = true)\n",
      " |-- team_id: double (nullable = true)\n",
      " |-- newteam_id: double (nullable = true)\n",
      " |-- curwin: double (nullable = true)\n",
      " |-- elo: double (nullable = true)\n",
      " |-- newelo: double (nullable = true)\n",
      " |-- season: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "dfelo = spark.createDataFrame(pdfelo)\n",
    "dfelo.printSchema()\n",
    "colNames = dfelo.columns\n",
    "for colName in colNames:\n",
    "    str1=\"e\"+colName\n",
    "    dfelo = dfelo.withColumnRenamed(colName,str1)\n",
    "dfhome=dfhome.join(dfelo, dfhome.game_id==dfelo.egame_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "stainless-joseph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dfhome=dfhome.drop(\"egame_id\",\"eteam_id\",\"enewteam_id\",\"enewwin\",\"eseason\",\"newgame_id\",\"elo\",\"newelo\",\"ecurwin\")\n",
    "dfhome.write.format(\"hive\").mode(\"overwrite\").saveAsTable(\"user_erin.nbabetting1\")\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "political-humanitarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: double (nullable = true)\n",
      " |-- game_id: integer (nullable = true)\n",
      " |-- team_id: double (nullable = true)\n",
      " |-- playoff: boolean (nullable = true)\n",
      " |-- season: string (nullable = true)\n",
      " |-- home: double (nullable = true)\n",
      " |-- realdate: date (nullable = true)\n",
      " |-- month: double (nullable = true)\n",
      " |-- year: double (nullable = true)\n",
      " |-- curwin: double (nullable = true)\n",
      " |-- fg: double (nullable = true)\n",
      " |-- fga: double (nullable = true)\n",
      " |-- fg_pct: double (nullable = true)\n",
      " |-- fg3: double (nullable = true)\n",
      " |-- fg3a: double (nullable = true)\n",
      " |-- fg3_pct: double (nullable = true)\n",
      " |-- ft: double (nullable = true)\n",
      " |-- fta: double (nullable = true)\n",
      " |-- ft_pct: double (nullable = true)\n",
      " |-- orb: double (nullable = true)\n",
      " |-- drb: double (nullable = true)\n",
      " |-- trb: double (nullable = true)\n",
      " |-- ast: double (nullable = true)\n",
      " |-- stl: double (nullable = true)\n",
      " |-- blk: double (nullable = true)\n",
      " |-- tov: double (nullable = true)\n",
      " |-- pf: double (nullable = true)\n",
      " |-- number_of_ots: double (nullable = true)\n",
      " |-- attendance: double (nullable = true)\n",
      " |-- win: double (nullable = true)\n",
      " |-- newteam_id: double (nullable = true)\n",
      " |-- newfg: double (nullable = true)\n",
      " |-- newfga: double (nullable = true)\n",
      " |-- newfg_pct: double (nullable = true)\n",
      " |-- newfg3: double (nullable = true)\n",
      " |-- newfg3a: double (nullable = true)\n",
      " |-- newfg3_pct: double (nullable = true)\n",
      " |-- newft: double (nullable = true)\n",
      " |-- newfta: double (nullable = true)\n",
      " |-- newft_pct: double (nullable = true)\n",
      " |-- neworb: double (nullable = true)\n",
      " |-- newdrb: double (nullable = true)\n",
      " |-- newtrb: double (nullable = true)\n",
      " |-- newast: double (nullable = true)\n",
      " |-- newstl: double (nullable = true)\n",
      " |-- newblk: double (nullable = true)\n",
      " |-- newtov: double (nullable = true)\n",
      " |-- newpf: double (nullable = true)\n",
      " |-- newnumber_of_ots: double (nullable = true)\n",
      " |-- newattendance: double (nullable = true)\n",
      " |-- newwin: double (nullable = true)\n",
      " |-- eelo: double (nullable = true)\n",
      " |-- enewelo: double (nullable = true)"
     ]
    }
   ],
   "source": [
    "dfhome.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "drawn-fitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
